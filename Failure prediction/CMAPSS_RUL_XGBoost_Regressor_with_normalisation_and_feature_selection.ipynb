{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "FDalluwXbsXk",
    "outputId": "55bc4fa6-803f-40be-84ab-f3c45e36e003"
   },
   "outputs": [],
   "source": [
    "'''from google.colab import drive\n",
    "drive.mount('/content/drive')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7bwRBIw1808g"
   },
   "outputs": [],
   "source": [
    "#!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "090U59DPJm7F"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sCVZb8EK9-RF"
   },
   "outputs": [],
   "source": [
    "#myfolder = \"./\"\n",
    "myfolder = \"../data/CMaps/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eK6zG_tsRZFx"
   },
   "source": [
    "# **Columns' names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "03uUZbfWF9Yj"
   },
   "outputs": [],
   "source": [
    "#Columns' names\n",
    "'''\n",
    "1)  unit number\n",
    "2)\ttime, in cycles\n",
    "3)\toperational setting 1\n",
    "4)\toperational setting 2\n",
    "5)\toperational setting 3\n",
    "6)\tsensor measurement  1\n",
    "7)\tsensor measurement  2\n",
    "...\n",
    "26)\tsensor measurement  21\n",
    "'''\n",
    "unitNames = ['UnitNumber']\n",
    "timeCycles = [\"TimeInCycles\"]\n",
    "operSets = [\"OperSet\"+str(i) for i in range(1,4)] # 1,2 et 3\n",
    "sensorMes = [\"SensorMes\"+str(j) for j in range(1, 22)] # de 1 à 21\n",
    "columnsNames = unitNames + timeCycles + operSets +sensorMes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pk7OEGaFRpHx"
   },
   "source": [
    "# **Datasets loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2zNavW8eUubj"
   },
   "outputs": [],
   "source": [
    "def data_loading(x):\n",
    "  train_path = myfolder + \"train_\"+ x +\".txt\"\n",
    "  test_path = myfolder + \"test_\"+ x +\".txt\"\n",
    "  rul_path = myfolder + \"RUL_\"+ x +\".txt\"\n",
    "  train = pd.read_csv(train_path, delim_whitespace=True, names=columnsNames)\n",
    "  test = pd.read_csv(test_path, delim_whitespace=True, names=columnsNames)\n",
    "  rul = pd.read_csv(rul_path, delim_whitespace=True, names=[\"RUL_FD\"])\n",
    "  return train, test, rul\n",
    "\n",
    "train_fd001, test_fd001, rul_fd001 = data_loading(\"FD001\")\n",
    "train_fd002, test_fd002, rul_fd002 = data_loading(\"FD002\")\n",
    "train_fd003, test_fd003, rul_fd003 = data_loading(\"FD003\")\n",
    "train_fd004, test_fd004, rul_fd004 = data_loading(\"FD004\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "id": "2D0p8HcQVpPu",
    "outputId": "c160f6b2-349b-4ce9-8f1d-5deb83cab107"
   },
   "outputs": [],
   "source": [
    "# Forcer l'affichage de toutes les colonnes\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "train_fd004.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-iHEenEWSFa2"
   },
   "source": [
    "# **RUL column generation for train and test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iQLmNp5STg3q"
   },
   "outputs": [],
   "source": [
    "def rul_train_generation(x):\n",
    "  rul = pd.DataFrame(x.groupby('UnitNumber')['TimeInCycles'].max()).reset_index()\n",
    "  rul.columns = ['UnitNumber', 'max']\n",
    "  x = x.merge(rul, on=['UnitNumber'], how='left')\n",
    "  x['RUL'] = x['max'] - x['TimeInCycles']\n",
    "  x.drop('max', axis=1, inplace=True)\n",
    "  return x\n",
    "\n",
    "train_fd001 = rul_train_generation(train_fd001)\n",
    "train_fd002 = rul_train_generation(train_fd002)\n",
    "train_fd003 = rul_train_generation(train_fd003)\n",
    "train_fd004 = rul_train_generation(train_fd004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "id": "2b0ThgOYbOJq",
    "outputId": "1820fff7-f818-483e-b9e1-5ff790abad39"
   },
   "outputs": [],
   "source": [
    "train_fd004.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SO9r-mpZXPjO"
   },
   "outputs": [],
   "source": [
    "def rul_test_generation(x, rul):\n",
    "\n",
    "  rul[\"UnitNumber\"] = rul.index + 1 # +1 pour que UnitNumber demarre de 1 au lieu de 0, car il s'agit du numero des moteur\n",
    "\n",
    "  x = x.merge(rul, on=['UnitNumber'], how='left')\n",
    "\n",
    "  max_cycle = pd.DataFrame(x.groupby('UnitNumber')['TimeInCycles'].max()).reset_index()\n",
    "  max_cycle.columns = ['UnitNumber', 'max']\n",
    "  x = x.merge(max_cycle, on=['UnitNumber'], how='left')\n",
    "  x['RUL'] = x['RUL_FD'] + x['max'] - x['TimeInCycles']\n",
    "  x.drop(['max', 'RUL_FD'], axis=1, inplace=True)\n",
    "\n",
    "  return x\n",
    "\n",
    "test_fd001 = rul_test_generation(test_fd001, rul_fd001)\n",
    "test_fd002 = rul_test_generation(test_fd002, rul_fd002)\n",
    "test_fd003 = rul_test_generation(test_fd003, rul_fd003)\n",
    "test_fd004 = rul_test_generation(test_fd004, rul_fd004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "id": "UsgIhGIrbbGe",
    "outputId": "499dda0b-cb37-4867-e165-bcc909b3e830"
   },
   "outputs": [],
   "source": [
    "test_fd004.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train_FD001: \",train_fd001.shape, \". test_FD001: \", test_fd001.shape,\". RUL: \", rul_fd001.shape)\n",
    "print(\"train_FD002: \",train_fd002.shape, \". test_FD002: \", test_fd002.shape,\". RUL: \", rul_fd002.shape)\n",
    "print(\"train_FD003: \",train_fd003.shape, \". test_FD003: \", test_fd003.shape,\". RUL: \", rul_fd003.shape)\n",
    "print(\"train_FD004: \",train_fd004.shape, \". test_FD004: \", test_fd004.shape,\". RUL: \", rul_fd004.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train_FD001: \",train_fd001.shape, \". test_FD001: \", test_fd001.shape,\". nbr moteurs\", len(train_fd001['UnitNumber'].unique()))\n",
    "print(\"train_FD002: \",train_fd002.shape, \". test_FD002: \", test_fd002.shape,\". nbr moteurs\", len(train_fd002['UnitNumber'].unique()))\n",
    "print(\"train_FD003: \",train_fd003.shape, \". test_FD003: \", test_fd003.shape,\". nbr moteurs\", len(train_fd003['UnitNumber'].unique()))\n",
    "print(\"train_FD004: \",train_fd004.shape, \". test_FD004: \", test_fd004.shape,\". nbr moteurs\", len(train_fd004['UnitNumber'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_fd002['UnitNumber'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Bivariate Correlation Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correl(df):\n",
    "    sns.heatmap(df.corr(),annot=True,cmap='RdYlGn',linewidths=0.2)\n",
    "    fig=plt.gcf()\n",
    "    fig.set_size_inches(20,20)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def correlation_analyz(df, seuil):\n",
    "  # Calculer la corrélation entre les variables avec différentes méthodes\n",
    "  corr_pearson = df.corr(method='pearson')\n",
    "  corr_spearman = df.corr(method='spearman')\n",
    "  corr_kendall = df.corr(method='kendall')\n",
    "\n",
    "  # Colonnes avec corrélation plus faible que le seuil pour chaque méthode\n",
    "  colonnes_faible_corr_pearson = corr_pearson.loc[corr_pearson['RUL'].abs() < seuil].index.tolist()\n",
    "  colonnes_faible_corr_spearman = corr_spearman.loc[corr_spearman['RUL'].abs() < seuil].index.tolist()\n",
    "  colonnes_faible_corr_kendall = corr_kendall.loc[corr_kendall['RUL'].abs() < seuil].index.tolist()\n",
    "\n",
    "  # Afficher les colonnes avec corrélation plus faible que le seuil pour chaque méthode\n",
    "  print(\"Colonnes avec corrélation plus faible que\", seuil, \"pour la corrélation de Pearson:\")\n",
    "  print(colonnes_faible_corr_pearson)\n",
    "  print(\"\\nColonnes avec corrélation plus faible que\", seuil, \"pour la corrélation de Spearman:\")\n",
    "  print(colonnes_faible_corr_spearman)\n",
    "  print(\"\\nColonnes avec corrélation plus faible que\", seuil, \"pour la corrélation de Kendall:\")\n",
    "  print(colonnes_faible_corr_kendall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correl(train_fd001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes avec corrélation plus faible que 0.6 pour la corrélation de Pearson:\n",
      "['UnitNumber', 'OperSet1', 'OperSet2', 'SensorMes3', 'SensorMes6', 'SensorMes8', 'SensorMes9', 'SensorMes13', 'SensorMes14']\n",
      "\n",
      "Colonnes avec corrélation plus faible que 0.6 pour la corrélation de Spearman:\n",
      "['UnitNumber', 'OperSet1', 'OperSet2', 'SensorMes6', 'SensorMes8', 'SensorMes9', 'SensorMes13', 'SensorMes14']\n",
      "\n",
      "Colonnes avec corrélation plus faible que 0.6 pour la corrélation de Kendall:\n",
      "['UnitNumber', 'TimeInCycles', 'OperSet1', 'OperSet2', 'SensorMes2', 'SensorMes3', 'SensorMes4', 'SensorMes6', 'SensorMes7', 'SensorMes8', 'SensorMes9', 'SensorMes11', 'SensorMes12', 'SensorMes13', 'SensorMes14', 'SensorMes15', 'SensorMes17', 'SensorMes20', 'SensorMes21']\n"
     ]
    }
   ],
   "source": [
    "correlation_analyz(train_fd001, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les colonnes à supprimer\n",
    "operSets_to_drop = [\"OperSet\"+str(i) for i in [1, 2]] # 1 et 2\n",
    "sensorMes_to_drop = [\"SensorMes\"+str(j) for j in [3, 6, 8, 9, 13, 14]]\n",
    "cols_to_drop = operSets_to_drop + sensorMes_to_drop\n",
    "\n",
    "# Suppression dans train et test\n",
    "drop_cols=True\n",
    "if(drop_cols == True):\n",
    "  train_fd001 = train_fd001.drop(cols_to_drop, axis=1)\n",
    "  test_fd001 = test_fd001.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['UnitNumber', 'TimeInCycles', 'OperSet3', 'SensorMes1', 'SensorMes2',\n",
       "        'SensorMes4', 'SensorMes5', 'SensorMes7', 'SensorMes10', 'SensorMes11',\n",
       "        'SensorMes12', 'SensorMes15', 'SensorMes16', 'SensorMes17',\n",
       "        'SensorMes18', 'SensorMes19', 'SensorMes20', 'SensorMes21', 'RUL'],\n",
       "       dtype='object'),\n",
       " 19)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fd001.columns, len(train_fd001.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correl(train_fd002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes avec corrélation plus faible que 0.03 pour la corrélation de Pearson:\n",
      "['UnitNumber', 'OperSet1', 'OperSet2', 'OperSet3', 'SensorMes1', 'SensorMes2', 'SensorMes3', 'SensorMes5', 'SensorMes6', 'SensorMes7', 'SensorMes8', 'SensorMes9', 'SensorMes10', 'SensorMes12', 'SensorMes13', 'SensorMes17', 'SensorMes18', 'SensorMes19', 'SensorMes20', 'SensorMes21']\n",
      "\n",
      "Colonnes avec corrélation plus faible que 0.03 pour la corrélation de Spearman:\n",
      "['UnitNumber', 'OperSet1', 'OperSet2', 'OperSet3', 'SensorMes1', 'SensorMes5', 'SensorMes10', 'SensorMes18', 'SensorMes19']\n",
      "\n",
      "Colonnes avec corrélation plus faible que 0.03 pour la corrélation de Kendall:\n",
      "['UnitNumber', 'OperSet1', 'OperSet2', 'OperSet3', 'SensorMes1', 'SensorMes5', 'SensorMes10', 'SensorMes18', 'SensorMes19']\n"
     ]
    }
   ],
   "source": [
    "correlation_analyz(train_fd002, 0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les colonnes à supprimer\n",
    "operSets_to_drop = [\"OperSet\"+str(i) for i in range(1,4)] # 1,2 et 3\n",
    "sensorMes_to_drop = [\"SensorMes\"+str(j) for j in [1, 5, 10, 18, 19]]\n",
    "cols_to_drop = operSets_to_drop + sensorMes_to_drop\n",
    "\n",
    "# Suppression dans train et test\n",
    "drop_cols=True\n",
    "if(drop_cols == True):\n",
    "  train_fd002 = train_fd002.drop(cols_to_drop, axis=1)\n",
    "  test_fd002 = test_fd002.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['UnitNumber', 'TimeInCycles', 'SensorMes2', 'SensorMes3', 'SensorMes4',\n",
       "        'SensorMes6', 'SensorMes7', 'SensorMes8', 'SensorMes9', 'SensorMes11',\n",
       "        'SensorMes12', 'SensorMes13', 'SensorMes14', 'SensorMes15',\n",
       "        'SensorMes16', 'SensorMes17', 'SensorMes20', 'SensorMes21', 'RUL'],\n",
       "       dtype='object'),\n",
       " 19)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fd002.columns, len(train_fd002.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correl(train_fd003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes avec corrélation plus faible que 0.4 pour la corrélation de Pearson:\n",
      "['UnitNumber', 'OperSet1', 'OperSet2', 'SensorMes6', 'SensorMes7', 'SensorMes10', 'SensorMes12', 'SensorMes15', 'SensorMes20', 'SensorMes21']\n",
      "\n",
      "Colonnes avec corrélation plus faible que 0.4 pour la corrélation de Spearman:\n",
      "['UnitNumber', 'OperSet1', 'OperSet2', 'SensorMes6', 'SensorMes7', 'SensorMes12', 'SensorMes15', 'SensorMes20', 'SensorMes21']\n",
      "\n",
      "Colonnes avec corrélation plus faible que 0.4 pour la corrélation de Kendall:\n",
      "['UnitNumber', 'OperSet1', 'OperSet2', 'SensorMes6', 'SensorMes7', 'SensorMes10', 'SensorMes12', 'SensorMes14', 'SensorMes15', 'SensorMes20', 'SensorMes21']\n"
     ]
    }
   ],
   "source": [
    "correlation_analyz(train_fd003, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les colonnes à supprimer\n",
    "operSets_to_drop = [\"OperSet\"+str(i) for i in [1, 2]] # 1 et 2\n",
    "sensorMes_to_drop = [\"SensorMes\"+str(j) for j in [6, 7, 10, 12, 15, 20, 21]]\n",
    "cols_to_drop = operSets_to_drop + sensorMes_to_drop\n",
    "\n",
    "# Suppression dans train et test\n",
    "drop_cols=True\n",
    "if(drop_cols == True):\n",
    "  train_fd003 = train_fd003.drop(cols_to_drop, axis=1)\n",
    "  test_fd003 = test_fd003.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['UnitNumber', 'TimeInCycles', 'OperSet3', 'SensorMes1', 'SensorMes2',\n",
       "        'SensorMes3', 'SensorMes4', 'SensorMes5', 'SensorMes8', 'SensorMes9',\n",
       "        'SensorMes11', 'SensorMes13', 'SensorMes14', 'SensorMes16',\n",
       "        'SensorMes17', 'SensorMes18', 'SensorMes19', 'RUL'],\n",
       "       dtype='object'),\n",
       " 18)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fd003.columns, len(train_fd003.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correl(train_fd004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes avec corrélation plus faible que 0.03 pour la corrélation de Pearson:\n",
      "['UnitNumber', 'OperSet1', 'OperSet2', 'OperSet3', 'SensorMes1', 'SensorMes2', 'SensorMes5', 'SensorMes6', 'SensorMes7', 'SensorMes8', 'SensorMes9', 'SensorMes10', 'SensorMes12', 'SensorMes13', 'SensorMes15', 'SensorMes18', 'SensorMes19', 'SensorMes20', 'SensorMes21']\n",
      "\n",
      "Colonnes avec corrélation plus faible que 0.03 pour la corrélation de Spearman:\n",
      "['UnitNumber', 'OperSet1', 'OperSet2', 'OperSet3', 'SensorMes1', 'SensorMes5', 'SensorMes7', 'SensorMes12', 'SensorMes15', 'SensorMes18', 'SensorMes19', 'SensorMes20', 'SensorMes21']\n",
      "\n",
      "Colonnes avec corrélation plus faible que 0.03 pour la corrélation de Kendall:\n",
      "['UnitNumber', 'OperSet1', 'OperSet2', 'OperSet3', 'SensorMes1', 'SensorMes5', 'SensorMes6', 'SensorMes7', 'SensorMes12', 'SensorMes15', 'SensorMes18', 'SensorMes19', 'SensorMes20', 'SensorMes21']\n"
     ]
    }
   ],
   "source": [
    "correlation_analyz(train_fd004, 0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les colonnes à supprimer\n",
    "operSets_to_drop = [\"OperSet\"+str(i) for i in range(1,4)] # 1,2 et 3\n",
    "sensorMes_to_drop = [\"SensorMes\"+str(j) for j in [1, 5, 6, 7, 12, 15, 18, 19, 20, 21]]\n",
    "cols_to_drop = operSets_to_drop + sensorMes_to_drop\n",
    "\n",
    "# Suppression dans train et test\n",
    "drop_cols=True\n",
    "if(drop_cols == True):\n",
    "  train_fd004 = train_fd004.drop(cols_to_drop, axis=1)\n",
    "  test_fd004 = test_fd004.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['UnitNumber', 'TimeInCycles', 'SensorMes2', 'SensorMes3', 'SensorMes4',\n",
       "        'SensorMes8', 'SensorMes9', 'SensorMes10', 'SensorMes11', 'SensorMes13',\n",
       "        'SensorMes14', 'SensorMes16', 'SensorMes17', 'RUL'],\n",
       "       dtype='object'),\n",
       " 14)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fd004.columns, len(train_fd004.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "_NZIBGyfZAdU"
   },
   "outputs": [],
   "source": [
    "def normalised_df(train, test):\n",
    "\n",
    "  from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "  # Instancier l'objet MinMaxScaler pour normaliser les données\n",
    "  scaler = MinMaxScaler()\n",
    "\n",
    "  # Normaliser train\n",
    "  train_scaled = scaler.fit_transform(train)\n",
    "  train_df = pd.DataFrame(train_scaled)\n",
    "\n",
    "  # Normaliser test\n",
    "  test_scaled = scaler.fit_transform(test)\n",
    "  test_df = pd.DataFrame(test_scaled)\n",
    "\n",
    "\n",
    "  train_df.columns = train.columns\n",
    "  test_df.columns = test.columns\n",
    "    \n",
    "  return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fd001, test_fd001 = normalised_df(train_fd001, test_fd001)\n",
    "train_fd002, test_fd002 = normalised_df(train_fd002, test_fd002)\n",
    "train_fd003, test_fd003 = normalised_df(train_fd003, test_fd003)\n",
    "train_fd004, test_fd004 = normalised_df(train_fd004, test_fd004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UnitNumber</th>\n",
       "      <th>TimeInCycles</th>\n",
       "      <th>SensorMes2</th>\n",
       "      <th>SensorMes3</th>\n",
       "      <th>SensorMes4</th>\n",
       "      <th>SensorMes8</th>\n",
       "      <th>SensorMes9</th>\n",
       "      <th>SensorMes10</th>\n",
       "      <th>SensorMes11</th>\n",
       "      <th>SensorMes13</th>\n",
       "      <th>SensorMes14</th>\n",
       "      <th>SensorMes16</th>\n",
       "      <th>SensorMes17</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130347</td>\n",
       "      <td>0.272082</td>\n",
       "      <td>0.212586</td>\n",
       "      <td>0.626983</td>\n",
       "      <td>0.269578</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.458604</td>\n",
       "      <td>0.993111</td>\n",
       "      <td>0.550773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.288660</td>\n",
       "      <td>0.590406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.647971</td>\n",
       "      <td>0.634407</td>\n",
       "      <td>0.511781</td>\n",
       "      <td>0.862888</td>\n",
       "      <td>0.601411</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.641234</td>\n",
       "      <td>0.992395</td>\n",
       "      <td>0.481761</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.608247</td>\n",
       "      <td>0.588561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.123646</td>\n",
       "      <td>0.271245</td>\n",
       "      <td>0.222481</td>\n",
       "      <td>0.627110</td>\n",
       "      <td>0.265759</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.456169</td>\n",
       "      <td>0.993056</td>\n",
       "      <td>0.531031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.278351</td>\n",
       "      <td>0.586716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UnitNumber  TimeInCycles  SensorMes2  SensorMes3  SensorMes4  SensorMes8  \\\n",
       "0         0.0      0.000000    0.130347    0.272082    0.212586    0.626983   \n",
       "1         0.0      0.001845    0.647971    0.634407    0.511781    0.862888   \n",
       "2         0.0      0.003690    0.123646    0.271245    0.222481    0.627110   \n",
       "\n",
       "   SensorMes9  SensorMes10  SensorMes11  SensorMes13  SensorMes14  \\\n",
       "0    0.269578     0.205128     0.458604     0.993111     0.550773   \n",
       "1    0.601411     0.358974     0.641234     0.992395     0.481761   \n",
       "2    0.265759     0.205128     0.456169     0.993056     0.531031   \n",
       "\n",
       "   SensorMes16  SensorMes17       RUL  \n",
       "0          0.0     0.288660  0.590406  \n",
       "1          0.0     0.608247  0.588561  \n",
       "2          0.0     0.278351  0.586716  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fd004.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "saXzvQieSZi7"
   },
   "source": [
    "# **Data splitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "lZWWDPa-QZ6A"
   },
   "outputs": [],
   "source": [
    "def data_split(train, test):\n",
    "\n",
    "  # data split\n",
    "  X_train = train.drop('RUL', axis=1)\n",
    "  Y_train = train['RUL']\n",
    "  X_test = test.drop('RUL', axis=1)\n",
    "  Y_test = test['RUL']\n",
    "    \n",
    "  return X_train, Y_train, X_test, Y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ME9D2ueVxeT"
   },
   "source": [
    "# **The XGBoost Regressor model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "ulZGXcj_Oold"
   },
   "outputs": [],
   "source": [
    "def my_xgboost_regressor(train, test):\n",
    "\n",
    "    X_train, Y_train, X_test, Y_test = data_split(train, test)\n",
    "\n",
    "    \n",
    "    # Créer le modèle XGBoost Regressor\n",
    "    model = XGBRegressor()\n",
    "\n",
    "    # Définir les paramètres à tester dans la recherche par grille\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 500, 1000],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.3], #np.logspace(-3,-1,10)\n",
    "        'subsample': [0.5, 0.7, 0.9],\n",
    "        'colsample_bytree': [0.5, 0.7, 0.9],\n",
    "        }\n",
    "\n",
    "    # Créer l'objet GridSearchCV\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "    # Effectuer la recherche par grille sur les données d'entraînement\n",
    "    grid_search.fit(X_train, Y_train)\n",
    "\n",
    "    # Afficher les meilleurs paramètres trouvés\n",
    "    print(\"Meilleurs paramètres trouvés :\")\n",
    "    print(grid_search.best_params_)\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''#-------------Train---------------------\n",
    "    # Prédire les valeurs en utilisant le modèle KNN Regressor pour les données Train\n",
    "    y_pred_train = grid_search.predict(X_train)\n",
    "    # Afficher l'erreur quadratique moyenne et le coefficient de détermination R2\n",
    "    mse_train = mean_squared_error(Y_train, y_pred_train)\n",
    "    rmse_train = np.sqrt(mse_train)\n",
    "    mae_train = mean_absolute_error(Y_train, y_pred_train)\n",
    "    mape_train = np.mean(np.abs((Y_train - y_pred_train) / Y_train)) * 100\n",
    "    r2_train = r2_score(Y_train, y_pred_train)\n",
    "    adjusted_r2_train = 1 - (1-r2_train)*(len(Y_train)-1)/(len(Y_train)-X_train.shape[1]-1)\n",
    "\n",
    "    print('\\n=============================Train=============================')\n",
    "    print('MSE : ',mse_train * 100,'%')\n",
    "    print('RMSE : ',rmse_train * 100,'%')\n",
    "    print('MAE : ',mae_train * 100,'%')\n",
    "    print('MAPE : ',mape_train,'%')\n",
    "    print('R2 : ',r2_train * 100,'%')\n",
    "    print('Adjusted R2 : ', adjusted_r2_train * 100,'%')'''\n",
    "\n",
    "    #-------------Test---------------------\n",
    "    # Prédire les valeurs en utilisant le modèle KNN Regressor pour les données Test\n",
    "    y_pred_test = grid_search.predict(X_test)\n",
    "    # Afficher l'erreur quadratique moyenne et le coefficient de détermination R2\n",
    "    mse_test = mean_squared_error(Y_test, y_pred_test)\n",
    "    rmse_test = np.sqrt(mse_test)\n",
    "    mae_test = mean_absolute_error(Y_test, y_pred_test)\n",
    "    mape_test = np.mean(np.abs((Y_test - y_pred_test) / Y_test)) * 100\n",
    "    r2_test = r2_score(Y_test, y_pred_test)\n",
    "    adjusted_r2_test = 1 - (1-r2_test)*(len(Y_test)-1)/(len(Y_test)-X_test.shape[1]-1)\n",
    "\n",
    "    print('\\n=============================Test=============================')\n",
    "    print('MSE : ',mse_test * 100,'%')\n",
    "    print('RMSE : ',rmse_test * 100,'%')\n",
    "    print('MAE : ',mae_test * 100,'%')\n",
    "    print('MAPE : ',mape_test,'%')\n",
    "    print('R2 : ',r2_test * 100,'%')\n",
    "    print('Adjusted R2 : ', adjusted_r2_test * 100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs paramètres trouvés :\n",
      "{'colsample_bytree': 0.5, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500, 'subsample': 0.5}\n",
      "\n",
      "=============================Test=============================\n",
      "MSE :  2.347415117814772 %\n",
      "RMSE :  15.321276440997897 %\n",
      "MAE :  11.171493064850031 %\n",
      "MAPE :  inf %\n",
      "R2 :  25.165767075427723 %\n",
      "Adjusted R2 :  25.06276056073459 %\n"
     ]
    }
   ],
   "source": [
    "my_xgboost_regressor(train_fd001, test_fd001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zOR36ak5T-vz"
   },
   "outputs": [],
   "source": [
    "my_xgboost_regressor(train_fd002, test_fd002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vNv5JIXlYCZU"
   },
   "outputs": [],
   "source": [
    "my_xgboost_regressor(train_fd003, test_fd003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0FI97PekYCbq",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_xgboost_regressor(train_fd004, test_fd004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_g6O1nMMzIbC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
